{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import process_mat_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from climate_extreme import ClimateExtreme\n",
    "import climate_stats as cs\n",
    "import scipy.stats as stats\n",
    "\n",
    "from BucketModel import BucketModel, BucketModelOptimizer\n",
    "from BucketModel.data_processing import preprocess_for_bucket_model, run_multiple_simulations\n",
    "from BucketModel.bucket_model_plotter import *\n",
    "\n",
    "from climate_simulation import run_model_for_future_climate, plot_climate_scenarios\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from generate_future_climate import generate_future_climate\n",
    "\n",
    "import os\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (WEEK 1) Simulating ensembles with the WeaGETS weather generator.\n",
    "### Reading in the input data and the output files from WeaGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path = \"/Users/cooper/Desktop/climate-impacts/data/Input_data.mat\"\n",
    "path_exp_first = \"/Users/cooper/Desktop/climate-impacts/data/Exponential/Seperated_FirstOrder_Exp_1500(30).mat\"\n",
    "path_gamma_third = \"/Users/cooper/Desktop/climate-impacts/data/Gamma/Seperated_ThirdOrder_Gamma_1500(30).mat\"\n",
    "\n",
    "present_data = process_mat_file(input_data_path)\n",
    "exp_first_data = process_mat_file(path_exp_first)\n",
    "gamma_third_data = process_mat_file(path_gamma_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "present_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_first_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at climate statistics to compare generated data to observed data\n",
    "### Comparing number of wet days (Precipitation > 0.1 mm) in the generated data to the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.plot_wet_days(\n",
    "    present_data,\n",
    "    exp_first_data,\n",
    "    \"/Users/cooper/Desktop/climate-impacts/images/wet_days.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Estimated Cumulative Distribution Function (ECDF) of the two datasets for Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.plot_ECDF(\n",
    "    observations=present_data,\n",
    "    simulation=exp_first_data,\n",
    "    column=\"Precipitation\",\n",
    "    xlabel=\"Precipitation (mm/day)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing mean and standard deviation of Average Temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.plot_mean_and_std(observations=present_data, simulation=exp_first_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit an extreme parameter distribution to the generated data and to the observed data and compare the confidence intervals of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = ClimateExtreme(present_data)\n",
    "generated = ClimateExtreme(exp_first_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, loc, scale, ci_lower, ci_upper = observed.fit_genextreme(\n",
    "    \"Precipitation\", quantile=0.95, n_bootstrap=1000\n",
    ")\n",
    "\n",
    "print(f\"GEV parameters: c={c:.4f}, loc={loc:.4f}, scale={scale:.4f}\")\n",
    "print(\"Confidence Intervals:\")\n",
    "print(f\"c: ({ci_lower[0]:.4f}, {ci_upper[0]:.4f})\")\n",
    "print(f\"loc: ({ci_lower[1]:.4f}, {ci_upper[1]:.4f})\")\n",
    "print(f\"scale: ({ci_lower[2]:.4f}, {ci_upper[2]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, loc, scale, ci_lower, ci_upper = generated.fit_genextreme(\n",
    "    \"Precipitation\", quantile=0.95, n_bootstrap=100\n",
    ")\n",
    "\n",
    "print(f\"GEV parameters: c={c:.4f}, loc={loc:.4f}, scale={scale:.4f}\")\n",
    "print(\"Confidence Intervals:\")\n",
    "print(f\"c: ({ci_lower[0]:.4f}, {ci_upper[0]:.4f})\")\n",
    "print(f\"loc: ({ci_lower[1]:.4f}, {ci_upper[1]:.4f})\")\n",
    "print(f\"scale: ({ci_lower[2]:.4f}, {ci_upper[2]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed.plot_fit_and_ci(\"Precipitation\", \"mm\")\n",
    "generated.plot_fit_and_ci(\"Precipitation\", \"mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = observed.compare_ci(\"Precipitation\", generated, \"Observed\", \"Generated\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if confidence intervals overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = all(\n",
    "    comparison[\"Observed_CI_upper\"] >= comparison[\"Generated_CI_lower\"]\n",
    ") and all(comparison[\"Generated_CI_upper\"] >= comparison[\"Observed_CI_lower\"])\n",
    "\n",
    "print(f\"Confidence intervals {'overlap' if overlap else 'do not overlap'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the distribution for visual comparison too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed.plot_extreme_comparison(\"Precipitation\", generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Truncated 2 sample KS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_stat, p_value = observed.truncated_ks_test(\"Precipitation\", generated, quantile=0.95)\n",
    "print(f\"KS statistic: {ks_stat:.4f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Bucket Model\n",
    "#### Preprocessing the data to match the format required by the Bucket Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_present_data = preprocess_for_bucket_model(present_data)\n",
    "processed_exp_first_data = preprocess_for_bucket_model(exp_first_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_present_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_exp_first_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the model for the catchment of Gsteig and the calibrated parameters from Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_model = BucketModel(\n",
    "    k=0.83, S_max=12.554, fr=0.111, rg=23.587, gauge_adj=0.267\n",
    ")  # Parameters from Assignment 2\n",
    "\n",
    "bucket_model.set_catchment_properties(\n",
    "    lapse_rate=0.5 / 100,  # °C/m\n",
    "    station_elevation=1638,  # m.a.s.l\n",
    "    basin_elevation=2035,  # m.a.s.l\n",
    "    snowmelt_temp_threshold=0,  # °C\n",
    "    latitude=46.9,\n",
    ")  # °N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the model for the present data and visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bucket_model.run(data=processed_present_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_water_balance(results=results, start_year=\"2010\", end_year=\"2019\")\n",
    "plot_timeseries(\n",
    "    results=results,\n",
    "    start_year=\"2010\",\n",
    "    end_year=\"2019\",\n",
    "    monthly=True,\n",
    "    plot_precipitation=True,\n",
    ")\n",
    "plot_timeseries(\n",
    "    results=results,\n",
    "    start_year=\"2010\",\n",
    "    end_year=\"2019\",\n",
    "    monthly=False,\n",
    "    plot_precipitation=True,\n",
    ")\n",
    "plot_monthly_boxplot(results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of how to run the model for each Simulation individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_results = run_multiple_simulations(\n",
    "    preprocessed_simulated_data=processed_exp_first_data,\n",
    "    bucket_model=bucket_model,\n",
    "    n_simulations=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean, ci = group_by_month_with_ci(multiple_results)\n",
    "\n",
    "plot_monthly_runoff_with_ci(monthly_mean, ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Week 2) Assessing the changes to streamflow in a future climate\n",
    "### Generating future climate ensembles based on delta change method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_future_climate(\n",
    "#     data=exp_first_data,\n",
    "#     name=\"exp_first\",\n",
    "#     output_folder=\"/Users/cooper/Desktop/climate-impacts/data/FutureExponentialTest\",\n",
    "# )\n",
    "\n",
    "generate_future_climate(\n",
    "    data=gamma_third_data,\n",
    "    name=\"gamma_third\",\n",
    "    output_folder=\"/Users/cooper/Desktop/climate-impacts/data/FutureGammaTest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate future streamflow using the future climate ensemble and the Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data_folder = \"/Users/cooper/Desktop/climate-impacts/data/FutureExponentialTest\"\n",
    "results = run_model_for_future_climate(\n",
    "    future_data_folder=future_data_folder,\n",
    "    bucket_model=bucket_model,\n",
    ")\n",
    "\n",
    "plot_climate_scenarios(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_analysis import UncertaintyAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_future_data = \"/Users/cooper/Desktop/climate-impacts/data/FutureExponentialTest/exp_first_CLMCOM-CCLM4-ECEARTH_RCP4.5.csv\"\n",
    "\n",
    "\n",
    "def prep_for_bucket_model(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess future climate data for the bucket model\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the future climate data\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Future climate data prepared for the bucket model\n",
    "    \"\"\"\n",
    "\n",
    "    date_cols = [\"Year\", \"Month\", \"Day\"]\n",
    "    future_data = pd.read_csv(path, parse_dates={\"Date\": date_cols}, dayfirst=True)\n",
    "\n",
    "    # Rename 'Precipitation' to 'P_mix'\n",
    "    future_data.rename(columns={\"Precipitation\": \"P_mix\"}, inplace=True)\n",
    "\n",
    "    # Set 'Date' as the index\n",
    "    future_data.set_index(\"Date\", inplace=True)\n",
    "\n",
    "    return future_data\n",
    "\n",
    "future_data = prep_for_bucket_model(path_to_future_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_climate_data(folder_path):\n",
    "    \"\"\"\n",
    "    Combine climate data from multiple CSV files into a single DataFrame.\n",
    "\n",
    "    This function reads climate data from CSV files in the specified folder, runs multiple simulations,\n",
    "    and combines the results into a single DataFrame with annual mean streamflow, climate model, and scenario.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing the climate data CSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame with columns for 'Simulation', 'Year', 'Streamflow', 'Climate_Model', and 'Scenario'.\n",
    "    \"\"\"\n",
    "    combined_data = []\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "    for filename in csv_files:\n",
    "        try:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            future_data = prep_for_bucket_model(file_path)\n",
    "            future_streamflow = run_multiple_simulations(\n",
    "                future_data, bucket_model, n_simulations=50\n",
    "            )\n",
    "            future_streamflow[\"Streamflow\"] = (\n",
    "                future_streamflow[\"Q_s\"] + future_streamflow[\"Q_gw\"]\n",
    "            )\n",
    "            future_streamflow[\"Year\"] = future_streamflow.index.year\n",
    "\n",
    "            # Extract model and scenario from filename\n",
    "            model, scenario = filename.rsplit(\"_\", 2)[-2:]\n",
    "            model = model.replace(\"-\", \"_\")\n",
    "            scenario = os.path.splitext(scenario)[0]\n",
    "\n",
    "            annual_totals = (\n",
    "                future_streamflow.groupby([\"Simulation\", \"Year\"])[\"Streamflow\"]\n",
    "                .sum()\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "            annual_mean = (\n",
    "                annual_totals.groupby([\"Simulation\"])[\"Streamflow\"]\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "            )\n",
    "            annual_mean[\"Climate_Model\"] = model\n",
    "            annual_mean[\"Scenario\"] = scenario\n",
    "\n",
    "            combined_data.append(annual_mean)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "    if combined_data:\n",
    "        return pd.concat(combined_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no data was processed\n",
    "\n",
    "folder_path = \"/Users/cooper/Desktop/climate-impacts/data/FutureGammaTest\"\n",
    "combined_df = combine_climate_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = UncertaintyAnalysis(combined_df)\n",
    "\n",
    "tu = uncertainty.calculate_tu('Streamflow')\n",
    "eu, eu_partition = uncertainty.calculate_eu('Streamflow', tu)\n",
    "cmu, cmu_partition = uncertainty.calculate_cmu('Streamflow', tu)\n",
    "su, su_partition = uncertainty.calculate_su('Streamflow', tu)\n",
    "\n",
    "print(f\"Total Uncertainty: {tu}\")\n",
    "print(f\"Emission Scenario Uncertainty: {eu} (Partition: {eu_partition})\")\n",
    "print(f\"Climate Model Uncertainty: {cmu} (Partition: {cmu_partition})\")\n",
    "print(f\"Stochastic Uncertainty: {su} (Partition: {su_partition})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BuckModEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
